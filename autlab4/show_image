#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#   Este nodo se suscribe a una imagen de ROS, la convierte en una matriz de
#   OpenCV y la muestra en pantalla
#

import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from std_msgs.msg import Int32

# Para mover el robot
from sensor_msgs.msg import LaserScan
from geometry_msgs.msg import Twist


class Cam(object):
    def __init__(self, topic_name="camera_frame"):
        self.bridge = CvBridge()
        self.image = np.zeros((10,10))
        isub = rospy.Subscriber(topic_name, Image, self.image_callback)

    def image_callback(self, img):
        self.image = self.bridge.imgmsg_to_cv2(img, "bgr8")

    def get_image(self):
        return self.image


# Lidar
class Lidar(object):
    def __init__(self):
        # Crear el suscriptor al tópico del LiDAR
        self.scan = LaserScan()
        topic = 'scan/'
        self.pub = rospy.Subscriber(topic, LaserScan, self.callback_point)
        # Esperar 1 segundo
        rospy.sleep(1)
        # Precalcular un vector de numpy que contenga los ángulos para cada
        # rango. Se puede usar numpy.arange, por ejemplo
        self.theta = np.arange(self.scan.angle_min, self.scan.angle_max + self.scan.angle_increment, self.scan.angle_increment)

        # Almacenar los rangos máximo y mínimo que puede leer el LiDAR
        self.max_range = self.scan.range_max
        self.min_range = self.scan.range_min
        
    def callback_point(self, msg):
        # Callback para el suscriptor
        self.scan = msg
        # print('RANGOS DEL CALLBACK: ', self.scan)

    def get_xy(self):
        # Obtener los rangos medidos
        ranges = list(self.scan.ranges)
        # Filtrar los rangos que no son válidos: mantener solo los rangos
        # válidos y sus correspondientes ángulos
        # obtener valor válidos dentro de los rangos
        x = []
        y = []
        for idx, val in enumerate(ranges):
            if val > self.scan.range_min or val < self.scan.range_max:
                x.append(val*np.cos(self.theta[idx]))
                y.append(val*np.sin(self.theta[idx]))
        # Convertir los rangos válidos en x, y
        x = np.array(x)
        y = np.array(y)
        return x , y

# Inicializar el nodo de ROS
rospy.init_node('camera_node')

# Objeto que se suscribe al tópico de la cámara
topic_name = "/camera/rgb/image_raw"
cam = Cam(topic_name)

# Tópico para publicar una imagen de salida
topic_pub = 'image_out'
pubimg = rospy.Publisher(topic_pub, Image, queue_size=10)

# Lidar
lidar = Lidar()

# Twist msg para mover al robot
twist = Twist()

topic = 'cmd_vel'
pub_twist = rospy.Publisher(topic, Twist, queue_size=10)

# Frecuencia del bucle principal
freq = 10
rate = rospy.Rate(freq)

count = 0
# Bucle principal

I_hue = np.zeros((10,10))
I_out = np.zeros((10,10))

while not rospy.is_shutdown():
    # Obtener la imagen del tópico de ROS en formato de OpenCV
    I = cam.get_image()
    li_x, li_y = lidar.get_xy()
    # Realizar algún tipo de procesamiento sobre la imagen
    if count > 0:

        Ihsv = cv2.cvtColor (I , cv2.COLOR_BGR2HSV )
        li_x, li_y = lidar.get_xy()
        # Segmentamos el color rojo
        lower_red = np.array([160, 50, 50])
        upper_red = np.array([180, 255, 255])

        mask = cv2.inRange(Ihsv, lower_red, upper_red)
        I_red = cv2.bitwise_and(I, I, mask=mask)

        # Aplicamos morfologia para cerrar la imagen
        k = cv2.getStructuringElement(cv2.MORPH_RECT,(35,35))
        closed = cv2.morphologyEx(I_red, cv2.MORPH_CLOSE, k)
        
        gray = cv2.cvtColor(closed,cv2.COLOR_BGR2GRAY)
        
        _, I_out = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
        
        x, y, w, h = cv2.boundingRect(I_out)
        cv2.rectangle(I, (x,y), (x+w, y+h), (0, 255 ,255), 2)
    
        # ######## ######## #######
        D = np.ones((2, len(li_x)))
        D[0, :] = li_x
        D[1, :] = li_y
        euc_dis = np.linalg.norm(D, axis=0)
        obstaculo_dis = euc_dis[euc_dis < 0.30]

        lata = (h > w) and (h > 205) and (w > 100)
        obstaculos = len(obstaculo_dis) > 0

        if lata: # Si se dibuja el cuadrado hasta cierto tamaño se de tiene
            twist.linear.x = 0.0
            twist.angular.z = 0.0
            print("Lata encontrada")
        elif obstaculos: # Si el obstaculo es esta cerca a menor de 0.30 
            twist.linear.x = -0.25
            twist.angular.z = -0.04
            print("Hay un obstaculo")
        else:
            print("Buscando lata ...")
            if count < 200:
                twist.linear.x = 0.0
                twist.angular.z = -0.25
                count = 0
            else:     
                twist.linear.x = 0.25
                twist.angular.z = 0.0

    # Mostrar la imagen
    cv2.imshow("Imagen Camara Turtlebot3", I)

    # Esperar al bucle para actualizar
    cv2.waitKey(1)
    count += 1
    pub_twist.publish(twist)
    # Opcional: publicar la imagen de salida como tópico de ROS
    #pubimg.publish(cam.bridge.cv2_to_imgmsg(I))
    rate.sleep()

cv2.destroyAllWindows()
